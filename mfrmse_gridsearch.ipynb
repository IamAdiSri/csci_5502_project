{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device='cuda'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from src.dataloaders import Dataset, PairwiseDataset\n",
    "from src.models import MatrixFactorizationRMSEModel, MatrixFactorizationBPRModel\n",
    "from src.trainer import Trainer\n",
    "from src.metrics import hitratio, ndcg\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# device = 'cpu'\n",
    "print(f\"{device=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.train_size=100000, dataset.test_size=943\n"
     ]
    }
   ],
   "source": [
    "class config:\n",
    "    data_dir = 'ml-100k'\n",
    "    neg_count = 10\n",
    "    epochs = 50\n",
    "    batch_size = 2048\n",
    "    dim = 40\n",
    "    lr = 0.1\n",
    "\n",
    "# dataset = Dataset(config.data_dir)\n",
    "dataset = PairwiseDataset(config.data_dir)\n",
    "dataset.gen_adjacency()\n",
    "dataset.make_train_test()\n",
    "print(f\"{dataset.train_size=}, {dataset.test_size=}\")\n",
    "\n",
    "metrics = {\n",
    "    # \"HR@1\": (hitratio, {\"top_n\": 1}),\n",
    "    # \"HR@5\": (hitratio, {\"top_n\": 5}),\n",
    "    \"HR@10\": (hitratio, {\"top_n\": 10}),\n",
    "    # \"NDCG@1\": (ndcg, {\"top_n\": 1}),\n",
    "    # \"NDCG@5\": (ndcg, {\"top_n\": 5}),\n",
    "    \"NDCG@10\": (ndcg, {\"top_n\": 10}),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# took 1 hour 15 mins to complete\n",
    "grid_params = {\n",
    "    \"lr\": [0.001, 0.01, 0.1, 1],\n",
    "    \"momentum\": list(np.arange(0.1, 1.1, 0.1)),\n",
    "    \"weight_decay\": [0.0001, 0.001, 0.01, 0.1, 1],\n",
    "}\n",
    "\n",
    "def search(lr, mom, wd):\n",
    "    # model = MatrixFactorizationRMSEModel(dataset.user_count, dataset.item_count, config.dim)\n",
    "    model = MatrixFactorizationBPRModel(dataset.user_count, dataset.item_count, config.dim)\n",
    "\n",
    "    # optimizer = torch.optim.Adam(model.parameters(), lr=config.lr, weight_decay=0.1)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=mom, nesterov=True, weight_decay=wd)\n",
    "\n",
    "    trainer = Trainer(dataset, model, optimizer, metrics, \n",
    "                    epochs=config.epochs, batch_size=config.batch_size,\n",
    "                    device=device, verbose=False, pbar=False)\n",
    "    \n",
    "    trainer.train(evaluate=True)\n",
    "    best_ndcg, best_ndcg_epoch = float('-inf'), 0\n",
    "    for i, s in enumerate(trainer.test_log):\n",
    "        if s['NDCG@10'] > best_ndcg:\n",
    "            best_ndcg = s['NDCG@10']\n",
    "            best_ndcg_epoch = i\n",
    "\n",
    "    return(best_ndcg, best_ndcg_epoch, (lr, mom, wd))\n",
    "\n",
    "output = Parallel(n_jobs=4)(delayed(search)(lr, mom, wd) for lr in grid_params['lr'] for mom in grid_params['momentum'] for wd in grid_params['weight_decay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9181/4076919080.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  ind = np.argmax(np.array(output_generator)[:, 0])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(127, (0.5835687783695144, 49, (0.1, 0.6, 0.01)))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = np.argmax(np.array(output_generator)[:, 0])\n",
    "ind, output_generator[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_log = sorted(output_generator)\n",
    "sorted_log.reverse()\n",
    "sorted_log\n",
    "\n",
    "with open(\"grid_log\", \"w\") as f:\n",
    "    for r in sorted_log:\n",
    "        f.write(f\"{r}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params = {\n",
    "    \"lr\": [0.001, 0.01, 0.1, 1],\n",
    "    \"momentum\": list(np.arange(0.1, 1.1, 0.1)),\n",
    "    \"weight_decay\": [0.0001, 0.001, 0.01, 0.1, 1],\n",
    "}\n",
    "\n",
    "best = float('-inf')\n",
    "best_params = None\n",
    "for lr in grid_params['lr']:\n",
    "    for mom in grid_params['momentum']:\n",
    "        for wd in grid_params['weight_decay']:\n",
    "            # model = MatrixFactorizationRMSEModel(dataset.user_count, dataset.item_count, config.dim)\n",
    "            model = MatrixFactorizationBPRModel(dataset.user_count, dataset.item_count, config.dim)\n",
    "\n",
    "            # optimizer = torch.optim.Adam(model.parameters(), lr=config.lr, weight_decay=0.1)\n",
    "            optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=mom, nesterov=True, weight_decay=wd)\n",
    "\n",
    "            trainer = Trainer(dataset, model, optimizer, metrics, \n",
    "                            epochs=config.epochs, batch_size=config.batch_size,\n",
    "                            device=device, verbose=False)\n",
    "            \n",
    "            trainer.train(evaluate=True)\n",
    "            best_ndcg, best_ndcg_epoch = float('-inf'), 0\n",
    "            for i, s in enumerate(trainer.test_log):\n",
    "                if s['NDCG@10'] > best_ndcg:\n",
    "                    best_ndcg = s['NDCG@10']\n",
    "                    best_ndcg_epoch = i\n",
    "            \n",
    "            if best_ndcg > best:\n",
    "                best = best_ndcg\n",
    "                best_params = [lr, mom, wd, best_ndcg_epoch]\n",
    "\n",
    "            print(best, best_params, (lr, mom, wd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = MatrixFactorizationRMSEModel(dataset.user_count, dataset.item_count, config.dim)\n",
    "model = MatrixFactorizationBPRModel(dataset.user_count, dataset.item_count, config.dim)\n",
    "\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=config.lr, weight_decay=0.1)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=config.lr, weight_decay=0.1)\n",
    "\n",
    "trainer = Trainer(dataset, model, optimizer, metrics, \n",
    "                  epochs=config.epochs, batch_size=config.batch_size,\n",
    "                  device=device, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(evaluate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Epoch 49: Avg Loss/Batch 20.135686           \n",
    "lr=0.1, weight_decay=0.01, batch_size=256                                               \n",
    "                                                   \n",
    "- HR@1: 0.27465535524920465\n",
    "- HR@5: 0.6246023329798516\n",
    "- HR@10: 0.7762460233297985\n",
    "- NDCG@1: 0.27465535524920465\n",
    "- NDCG@5: 0.45567622373046285\n",
    "- NDCG@10: 0.5050744632837261\n",
    "\n",
    "#### Epoch 49: Avg Loss/Batch 2.268884            \n",
    "lr=0.1, weight_decay=0.001, batch_size=256                             \n",
    "\n",
    "- HR@1: 0.271474019088017\n",
    "- HR@5: 0.6521739130434783\n",
    "- HR@10: 0.8154825026511134\n",
    "- NDCG@1: 0.271474019088017\n",
    "- NDCG@5: 0.46938699909136805\n",
    "- NDCG@10: 0.5226068198556473\n",
    "\n",
    "#### Epoch 49: Avg Loss/Batch 1.926479            \n",
    "lr=0.1, weight_decay=0.001, batch_size=128                             \n",
    "\n",
    "- HR@1: 0.31919406150583246\n",
    "- HR@5: 0.7104984093319194\n",
    "- HR@10: 0.8504772004241782\n",
    "- NDCG@1: 0.31919406150583246\n",
    "- NDCG@5: 0.5225957334522389\n",
    "- NDCG@10: 0.5683831099482718\n",
    "\n",
    "#### Epoch 49: Avg Loss/Batch 1.937064            \n",
    "lr=0.1, weight_decay=0.001, batch_size=128                             \n",
    " \n",
    "- HR@1: 0.3297985153764581\n",
    "- HR@5: 0.6839872746553552\n",
    "- HR@10: 0.848356309650053\n",
    "- NDCG@1: 0.3297985153764581\n",
    "- NDCG@5: 0.5171409534856304\n",
    "- NDCG@10: 0.5709949698866551\n",
    "\n",
    "#### Epoch 99: Avg Loss/Batch 1.799917            \n",
    "lr=0.1, weight_decay=0.001, batch_size=128        \n",
    "                                                   \n",
    "- HR@1: 0.3244962884411453\n",
    "- HR@5: 0.7232237539766702\n",
    "- HR@10: 0.8642629904559915\n",
    "- NDCG@1: 0.3244962884411453\n",
    "- NDCG@5: 0.5335037960184896\n",
    "- NDCG@10: 0.5796056642923276\n",
    "\n",
    "#### Epoch 143: Avg Loss/Batch 1.769505            \n",
    "lr=0.1, weight_decay=0.001, batch_size=128                                                   \n",
    "\n",
    "- HR@1: 0.3372216330858961\n",
    "- HR@5: 0.7253446447507953\n",
    "- HR@10: 0.8685047720042418\n",
    "- NDCG@1: 0.3372216330858961\n",
    "- NDCG@5: 0.5399725224060331\n",
    "- NDCG@10: 0.5865801610610061\n",
    "\n",
    "#### Epoch 99: Avg Loss/Batch 342.869812          \n",
    "lr=0.5, weight_decay=0.1, batch_size=131072                                                   \n",
    "\n",
    "HR@10: 0.8430540827147401\n",
    "NDCG@10: 0.554626786962534"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(trainer.model.state_dict(), \"saved_models/mf.pt\")\n",
    "# trainer.model.load_state_dict(torch.load(\"saved_models/mfbpr.pt\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
